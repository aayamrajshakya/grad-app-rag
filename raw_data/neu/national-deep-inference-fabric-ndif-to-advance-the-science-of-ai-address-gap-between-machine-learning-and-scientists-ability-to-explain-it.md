# National Deep Inference Fabric (NDIF) to advance the science of AI
Project will address gap between machine learning and scientists’ ability to explain it
## Lead PI
  * [David Bau](https://www.khoury.northeastern.edu/people/david-bau/)


## Co-PIs
  * [Arjun Guha](https://www.khoury.northeastern.edu/people/arjun-guha/)
  * [Jonathan Bell](https://www.khoury.northeastern.edu/people/jonathan-bell/)
  * [Carla Brodley](https://www.khoury.northeastern.edu/people/carla-brodley/)
  * [Byron Wallace](https://www.khoury.northeastern.edu/people/byron-wallace/)


Large neural networks can perform tasks of extraordinary complexity — but how they do it is one of the greatest mysteries in science today.
Why? Because unlike ordinary computer programs, machine learning systems are trained from data instead of being designed by a programmer. As a result, the internal workings of these systems are inscrutable to humans; they are black boxes, even to programmers.
The US National Science Foundation (NSF) has announced a $9 million grant to Northeastern University to launch National Deep Inference Fabric (NDIF), a new national-scale research computing infrastructure project that will enable researchers to delve into the mysteries of large-scale AI systems and address a growing gulf between the efficacy of machine learning and scientists’ ability to explain it.
The quest to unlock the black boxes goes well beyond a desire for increased understanding or knowledge — there are many critical implications to understanding how large networks work (such as with health care), and especially what information informs their output.
> “The strength of large neural networks is one of the greatest mysteries in science today.”  
> — David Bau, PI
## Abstract
The NDIF will develop a new kind of scientific computational infrastructure that will allow researchers to design scientific experiments by writing code that inspects and modifies the calculations deep within a network while it’s making predictions or conducting conversations. In other words, it will allow scientists to study how a network performs “inference”: how it processes inputs to yield outputs, and how its detailed internal computations lead to its predictions.
Instead of requiring every scientist to run their own copy of a large network to study — which would be prohibitively expensive — the new computational fabric will offer high-performance computing resources that will allow scientists to study shared neural networks configured for scientific study. Researchers will send experiments remotely to be conducted on large neural networks. “NDIF builds on top of recent innovations in deep learning software,” explains Jonathan Bell, assistant professor at Northeastern and co-PI. “Any user familiar with open-source neural network tools will be able to use their laptop to run experiments on the largest open language models.”
The computational capacity behind NDIF will be developed in partnership with the NSF DeltaAI project at the National Center for Supercomputing Applications (NCSA) at the University of Illinois, Urbana Champaign. “Artificial intelligence demands a new kind of high-performance computing infrastructure, in hardware, networking, and software,” says William Gropp, professor at UIUC and director of NCSA. “Working together, NDIF and the DeltaAI project will create a unique high-performance computational resource that will help maintain US scientific leadership at the cutting edge of artificial intelligence.”
NDIF is an open scientific collaboration that welcomes contributors and research collaborators from every discipline touched by artificial intelligence. The software underlying NDIF supports both small- and large-scale inference applications using either the NDIF or personal hardware, and it is suitable both for education and cutting-edge research.
As part of NDIF, the university will invite students and researchers across the country to participate in workshops on the methods, applications, and quickly evolving science of large-scale AI. With its eight campus locations throughout the United States, Northeastern University is uniquely situated to ensure the benefits of NDIF help build a next-generation AI-enabled workforce in every corner of the country. The students who participate in NDIF workshops will become part of a network of experts, providing embedded expertise within their own institutions and helping provide support that is responsive to local needs. As well, NDIF will partner with New America’s Public Interest Technology University Network (PIT-UN), a consortium of 63 universities and colleges, to ensure that the new NDIF research capabilities advance interdisciplinary research in the public interest.
Find information on how to participate as a researcher, educator, or open-source contributor at the [National Deep Inference Fabric website](https://ndif.us/).
## Funding
[NSF](https://www.nsf.gov/)
## Related Publications
  * Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. “Locating and Editing Factual Associations in GPT.” Advances in Neural Information Processing Systems 36 (2022).
  * Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau. “Mass Editing Memory in a Transformer.” The Eleventh International Conference on Learning Representations (ICLR); 2023.
  * Evan Hernandez, Arnab Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg, Yonatan Belinkov, and David Bau. “Linearity of Relation Decoding in Transformer Language Models.” Proceedings of the 2024 International Conference on Learning Representations. (ICLR 2024 spotlight)
  * Eric Todd, Millicent L. Li, Arnab Sen Sharma, Aaron Mueller, Byron C. Wallace, and David Bau. “Function Vectors in Large Language Models.” Proceedings of the 2024 International Conference on Learning Representations (ICLR 2024)
  * Nikhil Prakash, Tamar Rott Shaham, Tal Haklay, Yonatan Belinkov, and David Bau. “Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking.” Proceedings of the 2024 International Conference on Learning Representations (ICLR 2024).
  * Koyena Pal, Jiuding Sun, Andrew Yuan, Byron C. Wallace, and David Bau. “Future Lens: Anticipating Subsequent Tokens from a Single Hidden State.” SIGNLL Conference on Computational Natural Language Learning (CoNLL) (2023).


